<!doctype html>
<html>

<head>
  <script type="module" src="/src/main.ts"></script>
  <meta charset="UTF-8">
  <title>dmodel.ai</title>
  <meta name="description" content="dmodel: steerable and explainable AI">
  <link rel="canonical" href="https://d-model.ai">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/gh/bitmaks/cm-web-fonts@latest/fonts.css">

  <!-- Facebook Meta Tags -->
  <meta property="og:url" content="https://d-model.ai">
  <meta property="og:type" content="website">
  <meta property="og:title" content="d_model.ai">
  <meta property="og:description" content="steerable and explainable AI">
  <meta property="og:image" content="d_model.png">

  <!-- Twitter Meta Tags -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@d_model_ai">
  <meta property="twitter:domain" content="d-model.ai">
  <meta property="twitter:url" content="https://d-model.ai">
  <meta name="twitter:title" content="dmodel.ai">
  <meta name="twitter:description" content="steerable and explainable AI">
  <meta name="twitter:image" content="d_model.png">
  <style>
    body {
      margin: 50px auto;
      max-width: 650px;
      padding: 0 1rem;
    }

    h1 {
      margin-bottom: -5px;
      font-style: italic;
    }

    footer {
      max-width: fit-content;
      margin-left: auto;
    }
  </style>
</head>

<body>
  <h1>d<sub>model</sub> </h1>
  <b>look inside the model</b>

  <p>d<sub>model</sub> is an artificial intelligence research and deployment company.</p>
  <p>Closed model providers only sell you the next token. d<sub>model</sub> builds systems you can understand, steer,
    and retrain.</p>
  <p>We work with you to solve three key problems that are keeping artificial intelligence from better serving the
    world.</p>

  <h2><b>See the model</b></h2>
  <p>LLMs fail audits, leak secrets, and bias decisions because no one can explain a single answer. d<sub>model</sub>
    opens the modelâ€™s circuitry in real time, tracing each token through weights, activations, and prompts, so teams
    catch spurious correlations, verify safety constraints, and ship with confidence.</p>

  <h2><b>Shift the model</b></h2>
  <p>Models can decay before anyone notices. A quiet distribution shift can cause wrong diagnoses, throw off financial
    models, or trigger policy violations. d<sub>model</sub> watches live traffic, flags the features that moved, and
    triggers retraining before users notice.</p>

  <h2><b>Shape the model</b></h2>
  <p>Standard fine-tuning pipelines waste compute and invite reward hacking. d<sub>model</sub> is building a refinement
    fine-tuning service with built-in reward hacking probes and interpretable training curves that convert a base model
    into aligned, reliable tools.</p>

  <p>We're tackling some of the hardest problems in AI reliability and control. If you're deploying models in the wild
    or curious about how we work, we'd love to talk.</p>
  <p>Reach out to explore a pilot or collaboration.</p>
  <p>Join us if you want to shape the future of steerable, interpretable AI.</p>
  <footer><a href=blog />blog</a> | <a href="/team">team</a></footer>
</body>

</html>
